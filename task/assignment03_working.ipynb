{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75d94c43",
   "metadata": {},
   "source": [
    "# IT Incident SLA Comliance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df9e9a1",
   "metadata": {},
   "source": [
    "Service Level Agreement (SLA) compliance represents a critical performance metric in IT service management, directly impacting customer satisfaction, operational efficiency, and business continuity. This analysis examines cleaned IT incident data to identify systematic patterns affecting SLA compliance rates and builds predictive models to forecast potential SLA breaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "537599eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6729 entries, 0 to 6728\n",
      "Data columns (total 47 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   number                         6729 non-null   object \n",
      " 1   incident_state                 6729 non-null   object \n",
      " 2   active                         6729 non-null   bool   \n",
      " 3   reassignment_count             6729 non-null   int64  \n",
      " 4   reopen_count                   6729 non-null   int64  \n",
      " 5   sys_mod_count                  6729 non-null   int64  \n",
      " 6   made_sla                       6729 non-null   bool   \n",
      " 7   caller_id                      6727 non-null   object \n",
      " 8   opened_by                      6432 non-null   object \n",
      " 9   opened_at                      6729 non-null   object \n",
      " 10  sys_created_by                 3784 non-null   object \n",
      " 11  sys_created_at                 3784 non-null   object \n",
      " 12  sys_updated_by                 6729 non-null   object \n",
      " 13  sys_updated_at                 6729 non-null   object \n",
      " 14  contact_type                   6729 non-null   object \n",
      " 15  location                       6724 non-null   object \n",
      " 16  category                       6724 non-null   object \n",
      " 17  subcategory                    6723 non-null   object \n",
      " 18  symptom                        5137 non-null   object \n",
      " 19  impact                         6729 non-null   object \n",
      " 20  urgency                        6729 non-null   object \n",
      " 21  priority                       6729 non-null   object \n",
      " 22  assignment_group               6034 non-null   object \n",
      " 23  assigned_to                    6410 non-null   object \n",
      " 24  knowledge                      6729 non-null   bool   \n",
      " 25  u_priority_confirmation        6729 non-null   bool   \n",
      " 26  notify                         6729 non-null   object \n",
      " 27  closed_code                    6705 non-null   object \n",
      " 28  resolved_by                    6701 non-null   object \n",
      " 29  resolved_at                    6291 non-null   object \n",
      " 30  closed_at                      6729 non-null   object \n",
      " 31  isParent                       6729 non-null   object \n",
      " 32  closed_time_hours              6729 non-null   float64\n",
      " 33  sla_met                        6729 non-null   int64  \n",
      " 34  sla_status                     6729 non-null   object \n",
      " 35  knowledge_clean                6729 non-null   object \n",
      " 36  u_priority_confirmation_clean  6729 non-null   object \n",
      " 37  notify_clean                   6729 non-null   object \n",
      " 38  month                          6729 non-null   int64  \n",
      " 39  day_of_week                    6729 non-null   int64  \n",
      " 40  hour                           6729 non-null   int64  \n",
      " 41  is_weekend                     6729 non-null   bool   \n",
      " 42  complexity_level               6729 non-null   object \n",
      " 43  opened_hour                    6729 non-null   int64  \n",
      " 44  opened_day                     6729 non-null   int64  \n",
      " 45  is_business_hours              6729 non-null   bool   \n",
      " 46  opened_month                   6729 non-null   int64  \n",
      "dtypes: bool(6), float64(1), int64(10), object(30)\n",
      "memory usage: 2.1+ MB\n",
      "\n",
      "Dataset shape: (6729, 47)\n",
      "\n",
      "Target Variable Distribution:\n",
      "made_sla\n",
      "True     5813\n",
      "False     916\n",
      "Name: count, dtype: int64\n",
      "SLA Compliance Rate: 86.4%\n",
      "SLA Breach Rate: 13.6%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import shap\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns',\n",
    "              None)  # Display all columns in DataFrame output.\n",
    "pd.set_option('display.max_rows',\n",
    "              None)  # Display all rows in DataFrame output.\n",
    "# Load data from dataset\n",
    "df = pd.read_csv('../data/incidents_cleaned.csv')\n",
    "\n",
    "# Display DataFrame information\n",
    "df.info()\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"\\nTarget Variable Distribution:\")\n",
    "print(df['made_sla'].value_counts())\n",
    "print(f\"SLA Compliance Rate: {df['made_sla'].mean():.1%}\")\n",
    "print(f\"SLA Breach Rate: {(1 - df['made_sla'].mean()):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd46cfc",
   "metadata": {},
   "source": [
    "## 1. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab036cb",
   "metadata": {},
   "source": [
    "### 1.1 Operational Complexity Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "748ae9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ac0a0a",
   "metadata": {},
   "source": [
    "Rationale: EDA revealed sys_mod_count (r=-0.37) and reassignment_count (r=-0.25) as top predictors. Raw counts don't capture intensity (speed of handling), so we create ratio features normalized by incident duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54299497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Created 7 complexity features\n",
      "  ✓ Created 7 operational complexity features:\n",
      "    - mod_per_day, reassign_per_day, reopen_per_day (intensity ratios)\n",
      "    - activity_score (weighted complexity: mods + 2×reassigns + 3×reopens)\n",
      "    - has_reassignment, high_modification, is_complex (binary flags)\n",
      "\n",
      "  Validation - is_complex feature:\n",
      "    Simple incidents (0): 98.7% SLA compliance\n",
      "    Complex incidents (1): 69.4% SLA compliance\n",
      "    Performance gap: 29.2 percentage points\n"
     ]
    }
   ],
   "source": [
    "# Convert hours to days for readability\n",
    "# Add 0.01 to prevent division by zero for same-day incidents\n",
    "df_fe['closed_time_days'] = df_fe['closed_time_hours'] / 24 + 0.01\n",
    "\n",
    "# Intensity metrics: operations per day\n",
    "# High values indicate rapid, chaotic handling (bad sign)\n",
    "df_fe['mod_per_day'] = df_fe['sys_mod_count'] / df_fe['closed_time_days']\n",
    "df_fe['reassign_per_day'] = df_fe['reassignment_count'] / df_fe[\n",
    "    'closed_time_days']\n",
    "df_fe['reopen_per_day'] = df_fe['reopen_count'] / df_fe['closed_time_days']\n",
    "\n",
    "# Weighted activity score\n",
    "# Weights based on EDA impact: modifications (1x), reassignments (2x), reopens (3x)\n",
    "# Reopens weighted highest as they indicate failed resolution attempts\n",
    "df_fe['activity_score'] = (df_fe['sys_mod_count'] +\n",
    "                           df_fe['reassignment_count'] * 2 +\n",
    "                           df_fe['reopen_count'] * 3)\n",
    "\n",
    "# Binary complexity flags based on EDA-identified thresholds\n",
    "# has_reassignment: EDA showed 0 reassignments = 93.1% SLA vs 1+ = 84.8% SLA (8.3% gap)\n",
    "df_fe['has_reassignment'] = (df_fe['reassignment_count']\n",
    "                          > 0).astype(int)  # 93.1% vs 84.8%\n",
    "\n",
    "# high_modification: EDA showed 0-3 mods = >99% SLA vs 4+ mods = <95% SLA (threshold at 3)\n",
    "df_fe['high_modification'] = (df_fe['sys_mod_count'] > 3).astype(int)  # >99% vs <95%\n",
    "\n",
    "# is_complex: Combined threshold (>4 mods OR >2 reassignments)\n",
    "# Captures incidents requiring extensive handling regardless of type\n",
    "df_fe['is_complex'] = ((df_fe['sys_mod_count'] > 4) |\n",
    "                       (df_fe['reassignment_count'] > 2)).astype(int)\n",
    "\n",
    "print(f\"  ✓ Created 7 complexity features\")\n",
    "\n",
    "print(f\"  ✓ Created 7 operational complexity features:\")\n",
    "print(\n",
    "    f\"    - mod_per_day, reassign_per_day, reopen_per_day (intensity ratios)\")\n",
    "print(\n",
    "    f\"    - activity_score (weighted complexity: mods + 2×reassigns + 3×reopens)\"\n",
    ")\n",
    "print(f\"    - has_reassignment, high_modification, is_complex (binary flags)\")\n",
    "\n",
    "# Validate new feature\n",
    "complex_sla = df_fe.groupby('is_complex')['made_sla'].mean()\n",
    "print(f\"\\n  Validation - is_complex feature:\")\n",
    "print(f\"    Simple incidents (0): {complex_sla[0]:.1%} SLA compliance\")\n",
    "print(f\"    Complex incidents (1): {complex_sla[1]:.1%} SLA compliance\")\n",
    "print(\n",
    "    f\"    Performance gap: {(complex_sla[0]-complex_sla[1])*100:.1f} percentage points\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567d3905",
   "metadata": {},
   "source": [
    "### 1.2 Severity Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f04eea9",
   "metadata": {},
   "source": [
    "Rationale: Priority, Impact, and Urgency show strong multicollinearity (r=0.75-0.89), indicating they capture overlapping severity information. Using all three would introduce redundancy. We create binary \"high severity\" flags instead. EDA showed Priority has widest performance gap (Critical: 53.3% vs Low: 95.5% = 42.2% gap)From EDA: Priority shows 42.2% gap, but high multicollinearity with impact/urgency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddccb9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created 4 severity-based features:\n",
      "  - is_high_priority: 1 if Critical/High, 0 otherwise\n",
      "  - is_high_impact: 1 if High impact, 0 otherwise\n",
      "  - is_high_urgency: 1 if High urgency, 0 otherwise\n",
      "  - is_high_severity: 1 if ANY dimension is high, 0 otherwise\n",
      "\n",
      "Validation - is_high_severity feature:\n",
      "  Low severity (0): 87.4% SLA compliance\n",
      "  High severity (1): 54.9% SLA compliance\n",
      "  Performance gap: 32.5 percentage points\n"
     ]
    }
   ],
   "source": [
    "# Binary severity flags (convert categorical to 0/1)\n",
    "# 1 = High severity, 0 = Low severity\n",
    "df_fe['is_high_priority'] = df_fe['priority'].isin(\n",
    "    ['1 - Critical', '2 - High']).astype(int)\n",
    "df_fe['is_high_impact'] = df_fe['impact'].isin(['1 - High']).astype(int)\n",
    "df_fe['is_high_urgency'] = df_fe['urgency'].isin(['1 - High']).astype(int)\n",
    "\n",
    "# Combined severity flag: ANY dimension is high\n",
    "# Captures incidents marked as severe in at least one classification system\n",
    "df_fe['is_high_severity'] = ((df_fe['is_high_priority'] == 1) |\n",
    "                             (df_fe['is_high_impact'] == 1) |\n",
    "                             (df_fe['is_high_urgency'] == 1)).astype(int)\n",
    "\n",
    "print(\"✓ Created 4 severity-based features:\")\n",
    "print(\"  - is_high_priority: 1 if Critical/High, 0 otherwise\")\n",
    "print(\"  - is_high_impact: 1 if High impact, 0 otherwise\")\n",
    "print(\"  - is_high_urgency: 1 if High urgency, 0 otherwise\")\n",
    "print(\"  - is_high_severity: 1 if ANY dimension is high, 0 otherwise\")\n",
    "\n",
    "# Validate combined severity feature\n",
    "sev_sla = df_fe.groupby('is_high_severity')['made_sla'].mean()\n",
    "print(f\"\\nValidation - is_high_severity feature:\")\n",
    "print(f\"  Low severity (0): {sev_sla[0]:.1%} SLA compliance\")\n",
    "print(f\"  High severity (1): {sev_sla[1]:.1%} SLA compliance\")\n",
    "print(\n",
    "    f\"  Performance gap: {(sev_sla[0]-sev_sla[1])*100:.1f} percentage points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874f059e",
   "metadata": {},
   "source": [
    "### 1.3 Interaction Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c55a72c",
   "metadata": {},
   "source": [
    "Rationale: Combinations of factors may have compounding effects on SLA compliance. High severity + High complexity likely exhibits multiplicative negative impact rather than simple additive effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "170d4013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created 3 interaction features:\n",
      "  - severity_complexity: High severity AND complex incident\n",
      "  - confirmed_complex: Priority confirmed AND complex\n",
      "  - priority_reassign: High priority AND has reassignment\n",
      "\n",
      "Validation - severity_complexity feature:\n",
      "  No risk (0): 87.3% SLA compliance\n",
      "  High risk (1): 50.3% SLA compliance\n",
      "  Performance gap: 36.9 percentage points\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Feature Engineering Summary:\n",
      "  Original features: 51\n",
      "  New engineered features: 11\n",
      "  Total features after engineering: 62\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Critical interaction: High severity + High complexity\n",
    "# Worst-case scenario: urgent issue requiring extensive handling\n",
    "df_fe['severity_complexity'] = (df_fe['is_high_severity'] *\n",
    "                                df_fe['is_complex']).astype(int)\n",
    "\n",
    "# Priority confirmation + Complexity (from EDA: confirmation has 14.7% SLA gap)\n",
    "# Confirmed complex cases represent highest-risk incidents\n",
    "df_fe['confirmed_complex'] = (df_fe['u_priority_confirmation'] *\n",
    "                              df_fe['is_complex']).astype(int)\n",
    "\n",
    "# High priority + Reassignment\n",
    "# Urgent cases that got bounced around (routing failures on critical issues)\n",
    "df_fe['priority_reassign'] = (df_fe['is_high_priority'] *\n",
    "                              df_fe['has_reassignment']).astype(int)\n",
    "\n",
    "print(\"✓ Created 3 interaction features:\")\n",
    "print(\"  - severity_complexity: High severity AND complex incident\")\n",
    "print(\"  - confirmed_complex: Priority confirmed AND complex\")\n",
    "print(\"  - priority_reassign: High priority AND has reassignment\")\n",
    "\n",
    "# Validate most critical interaction\n",
    "risk_sla = df_fe.groupby('severity_complexity')['made_sla'].mean()\n",
    "print(f\"\\nValidation - severity_complexity feature:\")\n",
    "print(f\"  No risk (0): {risk_sla[0]:.1%} SLA compliance\")\n",
    "print(f\"  High risk (1): {risk_sla[1]:.1%} SLA compliance\")\n",
    "print(\n",
    "    f\"  Performance gap: {(risk_sla[0]-risk_sla[1])*100:.1f} percentage points\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(f\"Feature Engineering Summary:\")\n",
    "print(f\"  Original features: {df.shape[1]}\")\n",
    "print(f\"  New engineered features: {df_fe.shape[1] - df.shape[1]}\")\n",
    "print(f\"  Total features after engineering: {df_fe.shape[1]}\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091c0c95",
   "metadata": {},
   "source": [
    "### 1.4 Feature Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289c2770",
   "metadata": {},
   "source": [
    "#### 1.4.1 Ordinal Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ff6400",
   "metadata": {},
   "source": [
    "Priority, Impact, and Urgency have natural ordering from low to high severity. Preserve this ordering with numeric encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eff07bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc = df_fe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a297f08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Ordinal encoded 3 variables:\n",
      "  - priority_enc: 1 (Low) → 4 (Critical)\n",
      "  - impact_enc: 1 (Low) → 3 (High)\n",
      "  - urgency_enc: 1 (Low) → 3 (High)\n"
     ]
    }
   ],
   "source": [
    "# Priority (1=Low, 4=Critical)\n",
    "priority_map = {\n",
    "    '4 - Low': 1,\n",
    "    '3 - Moderate': 2,\n",
    "    '2 - High': 3,\n",
    "    '1 - Critical': 4\n",
    "}\n",
    "df_enc['priority_enc'] = df_enc['priority'].map(priority_map)\n",
    "\n",
    "# Impact (1=Low, 3=High)\n",
    "impact_map = {'3 - Low': 1, '2 - Medium': 2, '1 - High': 3}\n",
    "df_enc['impact_enc'] = df_enc['impact'].map(impact_map)\n",
    "\n",
    "# Urgency (1=Low, 3=High)\n",
    "urgency_map = {'3 - Low': 1, '2 - Medium': 2, '1 - High': 3}\n",
    "df_enc['urgency_enc'] = df_enc['urgency'].map(urgency_map)\n",
    "\n",
    "print(\"✓ Ordinal encoded 3 variables:\")\n",
    "print(\"  - priority_enc: 1 (Low) → 4 (Critical)\")\n",
    "print(\"  - impact_enc: 1 (Low) → 3 (High)\")\n",
    "print(\"  - urgency_enc: 1 (Low) → 3 (High)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789b1aaa",
   "metadata": {},
   "source": [
    "#### 1.4.2 Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6b8aef",
   "metadata": {},
   "source": [
    "assignment_group and category have many unique values without natural ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "729a5257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Label encoded 2 variables:\n",
      "  - assignment_group_enc: 65 unique groups\n",
      "  - category_enc: 47 unique categories\n"
     ]
    }
   ],
   "source": [
    "# assignment_group (from EDA: 56% performance variance across groups)\n",
    "le_group = LabelEncoder()\n",
    "df_enc['assignment_group'] = df_enc['assignment_group'].fillna('Unknown')\n",
    "df_enc['assignment_group_enc'] = le_group.fit_transform(\n",
    "    df_enc['assignment_group'])\n",
    "\n",
    "# category (from EDA: 21.1% performance gap)\n",
    "le_cat = LabelEncoder()\n",
    "df_enc['category'] = df_enc['category'].fillna('Unknown')\n",
    "df_enc['category_enc'] = le_cat.fit_transform(df_enc['category'])\n",
    "\n",
    "print(f\"✓ Label encoded 2 variables:\")\n",
    "print(f\"  - assignment_group_enc: {len(le_group.classes_)} unique groups\")\n",
    "print(f\"  - category_enc: {len(le_cat.classes_)} unique categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb5c2e4",
   "metadata": {},
   "source": [
    "#### 1.4.3 Binary Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748df727",
   "metadata": {},
   "source": [
    "Binary features created during feature engineering need to be explicitly typed as integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85788d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Verified 13 binary variables as integer type\n"
     ]
    }
   ],
   "source": [
    "binary_vars = [\n",
    "    'knowledge', 'u_priority_confirmation', 'made_sla', 'has_reassignment',\n",
    "    'high_modification', 'is_complex', 'is_high_priority', 'is_high_impact',\n",
    "    'is_high_urgency', 'is_high_severity', 'severity_complexity',\n",
    "    'confirmed_complex', 'priority_reassign'\n",
    "]\n",
    "\n",
    "for var in binary_vars:\n",
    "    if var in df_enc.columns:\n",
    "        df_enc[var] = df_enc[var].astype(int)\n",
    "\n",
    "verified_count = len([v for v in binary_vars if v in df_enc.columns])\n",
    "print(f\"✓ Verified {verified_count} binary variables as integer type\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp647_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
